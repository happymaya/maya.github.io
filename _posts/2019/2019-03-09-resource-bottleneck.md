---
title: 容易成为瓶颈的资源(03)
author:
  name: superhsc
  link: https://github.com/happymaya
date: 2019-03-09 21:24:11 +0800
categories: [Java, Performance Optimization]
tags: [性能优化, Performance Optimization]
math: true
mermaid: true
---

CPU、内存以及 I/O 三个资源是最容易成为瓶颈的。

## CPU

- 通过 top 命令，观测 CPU 性能；
- 通过负载，评估 CPU 任务执行的排队情况；
- 通过 vmstat，看 CPU 的繁忙程度。

### top 命令 —— CPU 性能

当进入 top 命令后，按 1 键即可看到每核 CPU 的运行指标和详细性能。
CPU 的使用有多个维度的指标，分别如下：
- `us`： 用户态所占用的 CPU 百分比，即引用程序所耗费的 CPU；
- `sy`： 内核态所占用的 CPU 百分比，需要配合 vmstat 命令，查看上下文切换是否频繁；
- `ni`： 高优先级应用所占用的 CPU 百分比；
- `wa`： 等待 I/O 设备所占用的 CPU 百分比，经常使用它来判断 I/O 问题，过高输入输出设备可能存在非常明显的瓶颈；
- `hi`： 硬中断所占用的 CPU 百分比；
- `si`： 软中断所占用的 CPU 百分比；
- `st`： 在平常的服务器上这个值很少发生变动，因为它测量的是宿主机对虚拟机的影响，即虚拟机等待宿主机 CPU 的时间占比，这在一些超卖的云服务器上，经常发生；
- `id`： 空闲 CPU 百分比。
一般地，应该比较关注空闲 CPU 的百分比，它可以从整体上体现 CPU 的利用情况。

> 正常业务 cpu 应在 90% 以下；load 超过了cpu数，则负载过高（需要迁移扩容），wa 过高（10%之上），可初步判断 io 问题。sy，si，hi，st，任何一个超过5%，都有问题。
{: .prompt-warning }

### 负载 —— CPU 任务排队情况

如果评估 CPU 任务执行的排队情况，那么需要通过**负载（load）**来完成。

除了 top 命令，使用 uptime 命令也能够查看负载情况，load 的效果是一样的，分别显示了最近 1min、5min、15min 的数值。

以单核操作系统为例，将 CPU 资源抽象成一条单向行驶的马路，则会发生以下三种情况：
- 马路上的车只有 4 辆，车辆畅通无阻，load 大约是 0.5；
- 马路上的车有 8 辆，正好能首尾相接安全通过，此时 load 大约为 1；
- 马路上的车有 12 辆，除了在马路上的 8 辆车，还有 4 辆等在马路外面，需要排队，此时 load 大约为 1.5。

那 load 为 1 代表的是啥？针对这个问题，误解还是比较多的。
> 这里需要注意的是，当 load 为 1 时，对于单核的硬件上就认为系统负载已经到了极限。这没有问题，但在多核硬件上，这种描述就不完全正确，它还与 CPU 的个数有关。例如：
- 单核的负载达到 1，总 load 的值约为 1；
- 双核的每核负载都达到 1，总 load 约为 2；
- 四核的每核负载都达到 1，总 load 约为 4。
所以，对于一个 load 到了 10，却是 16 核的机器，系统还远没有达到负载极限。
{: .prompt-warning }

### vmstat —— CPU 繁忙程度

要看 CPU 的繁忙程度，可以通过 vmstat 命令。

比较关注的有下面几列：
- `b`: 如果系统有负载问题，就可以看一下 b 列（**Uninterruptible Sleep**），它的意思是等待 I/O，可能是读盘或者写盘动作比较多；
- `si/so`： 显示了交换分区的一些使用情况，交换分区对性能的影响比较大，需要格外关注；
- `cs`: 每秒钟上下文切换（**Context Switch**）的数量，如果上下文切换过于频繁，就需要考虑是否是进程或者线程数开的过多。

每个进程上下文切换的具体数量，可以通过查看内存映射文件获取，如下代码所示：
```bash
[root@localhost ~]# cat /proc/2788/status
...
voluntary_ctxt_switches: 93950
nonvoluntary_ctxt_switches: 171204
```

## 内存
要想了解内存对性能的影响，则需要从操作系统层面来看一下内存的分布。如下图：
![]{http://assets.processon.com/chart_image/626edef9e401fd1b2465852f.png}

在平常写完代码后，比如写了一个 C++ 程序，去查看它的汇编，如果看到其中的内存地址，并不是实际的物理内存地址，那么应用程序所使用的，就是逻辑内存。学过计算机组成结构的同学应该都有了解。

逻辑地址可以映射到两个内存段上：**物理内存**和**虚拟内存**，那么整个系统可用的内存就是两者之和。比如你的物理内存是 4GB，分配了 8GB 的 SWAP 分区，那么应用可用的总内存就是 12GB。
> 
- 共享内存：可以被多个进程共享的内存。比如加载到内存的 libjvm.so，可以被多个虚拟机使用，不用每个加载一份；
- 虚拟内存（SWAP 分区）：划一块磁盘充当内存，格式就是 `SWAP`。它能当内存用但并不是内存；
- 物理内存：机器的配置，比如 4 GB；
- 机器的**可用内存=物理内存+虚拟内存** ；
- 逻辑内存：和程序运行有关，和内存占用无关。就是使用硬件，将二进制中的逻辑内存（一份exe的逻辑地址都是固定的），翻译成实际的可用内存。
{: .prompt-warning }

### top 命令
从 top 命令可以内存的几个参数，可以注意方块框起来的三个区域，解释如下：
- `VIRT`： 这里是指虚拟内存，一般比较大，不用做过多关注；
- `RES`： 我们平常关注的是这一列的数值，它代表了进程实际占用的内存，平常在做监控时，主要监控的也是这个数值；
- `SHR`： 指的是共享内存，比如可以复用的一些 so 文件等。

### CPU 缓存

由于 CPU 和内存之间的速度差异非常大，解决方式就是**加入高速缓存**。实际上，这些高速缓存往往会有多层，如下图所示：
![](http://assets.processon.com/chart_image/626ee075e0b34d07454666ff.png)

>  高速缓存指的是 CPU 的 L1，L2，L3 甚至 Ln 层缓存。CPU 缓存离 CPU 最近，但由于材质（SRAM）比较贵，所以容量很小，比如一级缓存可能只有32KB。在 Linux 下，可以通过查看 /sys/devices/system/cpu/cpu0/cache 下面的文件，查看高速缓存的配置规格。
{: .prompt-warning }

Java 有大部分知识点是围绕多线程的，那是因为，如果一个线程的时间片跨越了多个 CPU，那么就会存在同步问题。

在 Java 中，和 CPU 缓存相关的最典型的知识点，就是在并发编程中，针对 Cache line 的伪共享（False Sharing）问题。

伪共享指的是在这些高速缓存中，以缓存行为单位进行存储，哪怕你修改了缓存行中一个很小很小的数据，它都会整个刷新。所以，当多线程修改一些变量的值时，如果这些变量都在同一个缓存行里，就会造成频繁刷新，无意中影响彼此的性能。

CPU 的每个核，基本是相同的，拿 CPU0 来说，可以通过以下的命令查看它的缓存行大小，这个值一般是 64。
```bash
cat /sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size
cat /sys/devices/system/cpu/cpu0/cache/index1/coherency_line_size
cat /sys/devices/system/cpu/cpu0/cache/index2/coherency_line_size
cat /sys/devices/system/cpu/cpu0/cache/index3/coherency_line_size
```

当然，通过 cpuinfo 也能得到一样的结果：
```bash
# cat /proc/cpuinfo | grep cache
cache size	: 20480 KB
cache_alignment	: 64
cache size	: 20480 KB
cache_alignment	: 64
cache size	: 20480 KB
cache_alignment	: 64
cache size	: 20480 KB
cache_alignment	: 64
```
在 JDK 8 以上的版本，通过开启参数 `-XX:-RestrictContended`，就可以使用注解 `@sun.misc.Contended` 进行补齐，来避免伪共享的问题。

### HugePage
![]{http://assets.processon.com/chart_image/626edef9e401fd1b2465852f.png}
再回顾一下上文提到的这张图，上面有一个 TLB 组件，它的速度很快，但容量有限，在普通的 PC 机上没有什么瓶颈。但如果机器配置比较高，物理内存比较大，那就会产生非常多的映射表，CPU 的检索效率也会随之降低。

传统的页大小是 4 KB，在大内存时代这个值偏小了，解决的办法就是增加页的尺寸，比如将其增加到 2 MB，这样，就可以使用较少的映射表来管理大内存。而这种将页增大的技术，就是 **Huge Page**。
![](http://assets.processon.com/chart_image/626ee3041e08535fe5426e4f.png)

同时，HugePage 也伴随着一些副作用，比如**竞争加剧**，但在一些大内存的机器上，开启后在一定程度上会增加性能。

### 预先加载
另外，一些程序的默认行为也会对性能有所影响，比如 JVM 的 `-XX:+AlwaysPreTouch` 参数。

默认情况下，JVM 虽然配置了 `Xmx`、`Xms` 等参数，指定堆的初始化大小和最大大小，但它的内存在真正用到时，才会分配；但如果加上 AlwaysPreTouch 这个参数，JVM 会在启动的时候，就把所有的内存预先分配。

这样，启动时虽然慢了些，但运行时的性能会增加。

## I/O

I/O 设备是计算机里速度最慢的组件，它指的不仅仅是硬盘，还包括外围的所有设备。

在无视不同设备的实现细节的情况下，直接看它的写入速度：

**缓冲区是解决速度差异的唯一工具。**单在一些极端的情况下，比如断电时，就产生了太多的不确定性，这时的缓存区，都容易丢！！！


### isotat

最能体现 I/O 繁忙程度的，就是 `top 命令`和 `vmstat 命令`的 `wa%`.

当应用写入大量的日志，I/O wait 就可能非常高。

最便捷好用查看磁盘 I/O 的工具，就是 `iostat 命令` 。而 iostat 命令通过 sysstat 包进行安装。

主要的指标如下：
- `%util`：需要非常关注这个数值，通常情况下，这个数字超过 80%，就证明 I/O 的负荷已经非常严重了；
- `Device`：表示是哪块硬盘，如果有多块磁盘，则会显示多行；
- `avgqu-sz`：**平均请求队列的长度**，这和十字路口排队的汽车也非常类似。显然，这个值越小越好；
- `awai`：**响应时间**包含了**队列时间**和**服务时间**。它有一个经验值，通常情况下应该是小于 5ms 的，如果这个值超过了 10ms，则证明等待的时间过长了；
- `svctm`：表示操作 I/O 的平均服务时间。在这里就是 AVG 的意思。svctm 和 await 是强相关的，如果它们比较接近，则表示 I/O 几乎没有等待，设备的性能很好；但如果 await 比 svctm 的值高出很多，则证明 I/O 的队列等待时间太长，进而系统上运行的应用程序将变慢。


### 零拷贝

硬盘上的数据，在发往网络之前，需要经过多次**缓冲区的拷贝**，以及**用户空间**和**内核空间**的多次切换。如果能减少一些拷贝的过程，效率就能提升，所以零拷贝应运而生。

零拷贝是一种非常重要的性能优化手段，比如常见的 **Kafka、Nginx **等，就使用了这种技术。

有无零拷贝之间的区别，如下：

(1) 没有采取零拷贝手段

传统方式中要想将一个文件的内容通过 Socket 发送出去，则需要经过以下步骤：
1. 将文件内容拷贝到内核空间；
2. 将内核空间内存的内容，拷贝到用户空间内存，比如 Java 应用读取 zip 文件；
3. 用户空间将内容写入到内核空间的缓存中；
4. Socket 读取内核缓存中的内容，发送出去。

(2) 采取了零拷贝手段
零拷贝有多种模式，比如 sendfile 。如下图所示，在内核的支持下，零拷贝少了一个步骤，那就是内核缓存向用户空间的拷贝，这样既节省了内存，也节省了 CPU 的调度时间，让效率更高。

![](http://assets.processon.com/chart_image/62654eeb7d9c084c42df0fa3.png)

在内核的支持下，零拷贝少了一个步骤，那就是内核缓存向用户空间的拷贝。底层实现，可以参考 sendfile 函数。典型的应用如 netty 的 zero copy，kafka 的文件传输，nginx 的大文件传输等。只要数据不需要经过二次加工发送出去，都可以使用零拷贝，非常适合下载这种场景。

> kafka 对磁盘操作是顺序读写，顺序读写操作要比随机读写速度快很多，再加上使用零拷贝技术所以其吞吐量非常高，主要有 5 点：
 1. Cache/Filesystem Cache PageCache缓存
 2. 顺序读写 由于现代的操作系统提供了预读和写技术，磁盘的顺序写大多数情况下比随机写内存还要快。 
 3. Zero-copy 零拷⻉，少了一次内存交换。 
 4. Batching of Messages 批量量处理。合并小的请求，然后以流的方式进行交互，直顶网络上限。
 5. Pull 拉模式 使用拉模式进行消息的获取消费，与消费端处理能力相符。
{: .prompt-warning }

## 总结

通过使用一些性能命令观测 CPU、内存以及 I/O，可以帮助我们大体猜测性能问题发生的地方。但是它们对于性能问题，只能起到辅助作用，不能精准地定位到真正的性能瓶颈，还需要做更多深入的排查工作，收集更多信息。

