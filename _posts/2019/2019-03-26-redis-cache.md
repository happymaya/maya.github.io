---
title: Redis（08）
author:
  name: superhsc
  link: https://github.com/happymaya
date: 2019-03-25 23:33:00 +0800
categories: [Java, Performance Optimization]
tags: [性能优化, Performance Optimization]
math: true
mermaid: true
---

堆内缓存的特点、注意事项以及使用的场景，对于分布式缓存来说，同样适用。

**分布式缓存**，一种**集中管理**的思想。假如服务是多节点，堆内缓存在每个节点上都会有一份；而分布式缓存，所有的节点，共用一份缓存，既节约了空间，又减少了管理成本。

在分布式缓存领域，使用最多的就是 Redis.

Redis 支持非常丰富的数据类型，包括字符串（String）、列表（list）、集合（set）、有序集合（zset）、哈希表（hash）等常用的数据结构。除此之外，它也支持也写其它的比如为图（bitmap） 一类的数据结构。

每当提到 Redis，就不得不提一下另一个分布式缓存 Memcached，以下简称 MC。MC 现在已经很少使用了，但它们之间的区别，还是需要了解的：

|            | Redis                            | MC                                           |
| ---------- | -------------------------------- | -------------------------------------------- |
| 是否多线程 | 否                               | 是                                           |
| 数据类型   | 数据类型丰富                     | 字符串类型                                   |
| 数据保存   | 数据可持久化到硬盘               | 断电后数据会丢失                             |
| 性能表现   | 存储小数据时性能高               | 存储大数据（如超 100 kb）性能高              |
| 数据划分   | 使用基于哈希槽（slot）的划分方式 | 客户端实现的一致性哈希（ConsistencyHashing） |


## SpringBoot 使用 Redis

使用 SpringBoot 很容易地对 Redis 进行操作。

Java 的 Redis 的客户端，常用的有三个：**jedis**、**redissoon** 和 **lettuce**。

Spring 默认使用的是 lettuce。lettuce 是使用 netty 开发的，操作是异步的，性能比常用的 jedis 要高，redisson 也是异步的，但它对常用的业务操作进行了封装，适合有业务含义的代码。

通过下面的 jar 包，即可方便地使用 Redis。
```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-redis</artifactId>
</dependency>
```
上面这种方式，主要是使用 RedisTemplate 这个类。它针对不同的数据类型，抽象了相应的方法组。

另外一种方式，是使用 Spring 抽象的缓存包 spring-cache。它使用注解，采用 AOP 的方式，对 Cache 层进行了抽象，可以在各种堆内缓存框架和分布式框架之间进行切换。下面是它的 maven 坐标：
```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-cache</artifactId>
</dependency>
```
> 与 spring-cache 类似的，还有阿里的 jetcache，都是比较好用的。
{: .prompt-tip }

## 秒杀业务介绍

秒杀，是对正常业务流程的考验。因为会产生突发流量，平常一天的请求，可能集中在几秒内就要完成。比如，某些抢购，可能库存就几百个，但是瞬时进入的流量可能是几十上百万。

![](http://assets.processon.com/chart_image/6270a63e5653bb5be570a400.png)

如果参与秒杀的人，等待很长时间，体验就非常差，想象一下拥堵的高速公路收费站，就能理解秒杀者的心情。同时，被秒杀的资源会成为热点，发生并发争抢的后果。比如 12306 的抢票，如果单纯使用数据库来接受这些请求，就会产生严重的锁冲突，这也是秒杀业务难的地方。

此时，秒杀前端需求与数据库之间的速度是严重不匹配的，而且秒杀的资源是热点资源。这种场景下，采用缓存是非常合适的。

处理秒杀业务有三个绝招：
1. 选择速度最快的内存作为数据写入；
2. 使用异步处理替代同步请求；
3. 使用分布式横向扩展

## Lua 脚本完成秒杀
秒杀可以分为一下三个阶段：
1. **准备阶段**，会提前载入一些必需的数据到缓存中，并提前预热业务数据，用户会不断刷新页面，来查看秒杀是否开始；
2. **抢购阶段**，就是我们通常说的秒杀，会产生瞬时的高并发流量，对资源进行集中操作；
3. **结束清算**，主要完成数据的一致性，处理一些异常情况和回仓操作。

![](http://assets.processon.com/chart_image/6270a786e401fd1b2467825d.png)

最重要的是秒杀阶段。可以设计一个 Hash 数据结构，来支持库存的扣减：
```bash
seckill:goods:${goodsId}{ total: 100, start: 0, alloc:0 }
```
这个 Hash 数据结构中，有三个重要部分：
- total 是一个静态值，表示要秒杀商品的数量，在秒杀开始前，会将这个数值载入到缓存中；
- start 是一个布尔值。秒杀开始前的值为 0；通过后台或者定时，将这个值改为 1，则表示秒杀开始；
- 此时，alloc 将会记录已经被秒杀的商品数量，直到它的值达到 total 的上限。
```java
static final String goodsId = "seckill:goods:%s"; 
String getKey(String id) { 
    return String.format(goodsId, id); 
} 
public void prepare(String id, int total) {
    String key = getKey(id); 
    Map<String, Integer> goods = new HashMap<>(); 
    goods.put("total", total); 
    goods.put("start", 0); 
    goods.put("alloc", 0); 
    redisTemplate.opsForHash().putAll(key, goods); 
}
```

秒杀的时候，首先需要判断库存，才能够对库存进行锁定。这两步动作并不是**原子的**，在分布式环境下，多个节点同时对 Redis 进行操作，就会发生同步问题。

为了解决同步问题，一种方式就是使用 Lua 脚本，把这些操作封装起来，这样就能保证**原子性**。
此外一种方式是是使用**分布式锁**。

下面是一个调式好的 Lua 脚本，可以看到一些关键的比较动作，和 HiNCRBY 命令，能够成为一个原子操作。
```lua
local falseRet = "0" 
local n = tonumber(ARGV[1]) 
local key = KEYS[1] 
local goodsInfo = redis.call("HMGET",key,"total","alloc") 
local total = tonumber(goodsInfo[1]) 
local alloc = tonumber(goodsInfo[2]) 
if not total then 
    return falseRet 
end 
if total >= alloc + n  then 
    local ret = redis.call("HINCRBY",key,"alloc",n) 
    return tostring(ret) 
end 
return falseRet
```
对应的秒杀代码如下，由于使用的是 String 的序列化方式，所以会把库存的扣减数量先转化为字符串，然后再调用 Lua 脚本。
```java
public int secKill(String id, int number) { 
    String key = getKey(id); 
    Object alloc =  redisTemplate.execute(script, Arrays.asList(key), String.valueOf(number)); 
    return Integer.valueOf(alloc.toString()); 
}
```
执行仓库里的 testSeckill 方法。启动 1000 个线程对 100 个资源进行模拟秒杀，可以看到生成了 100 条记录，同时其他的线程返回的是 0，表示没有秒杀到。

## 分布式缓存系统带来的问题

### 1. 缓存穿透

如果缓存的命中率很低，压力就会集中在数据库持久层。

如果找到相关数据，就可以把它缓存起来。但问题是，**假如某次请求，在缓存和持久层都没有命中，这种情况叫做缓存的穿透。**
![缓存穿透](http://assets.processon.com/chart_image/6270b2d71efad45d06d5006f.png)

栗子：假设，有一个登录系统，有外部攻击，一直尝试使用不存在的用户进行登录，这些用户都是虚拟的，不能有效地被缓存起来，每次都会到数据库中查询一次，最后就会造成服务的性能障碍。

解决这种问题有两种方案：
- 第一种，将空对象缓存起来。不是持久层查不到数据？那么久可以把本次请求的结果设置为 null，然后放入到缓存中。通过设置合理的过期时间，就可以保证后端数据库的安全；
- 缓存空对象会占用额外的缓存空间，还会有数据不一致的时间窗口，所以**第二种**方法就是针对大数据量的、有规律的键值，使用布隆过滤器进行处理。一条记录存在与不存在，是一个 Bool 值，只需要使用 1 比特就可存储。**布隆过滤器**就可以把这种是、否操作，压缩到一个数据结构中。比如手机号，用户性别这种数据，就非常适合使用布隆过滤器。

### 2. 缓存击穿

缓存击穿，指的也是用户请求落在数据库上的情况，大多数情况，是**由于缓存时间批量过期引起的**。

一般会对缓存中的数据，设置一个过期时间。如果在某个时刻从数据库获取了大量数据，并设置了同样的过期时间，它们将会在同一时刻失效，造成缓存的击穿。

对于比较热点的数据，就可以设置它不过期；或者在访问的时候，更新它的过期时间；批量入库的缓存项，也尽量分配一个比较平均的过期时间，避免同一时间失效。

### 3. 缓存雪崩

雪崩，这种情况比较严重。缓存是用来对系统加速的，后端的数据库只是数据的备份，而不是作为高可用的备选方案。

当缓存系统出现故障，流量会瞬间转移到后端的数据库。没有多长时间，数据库将会被大流量压垮挂掉，这种级联式的服务故障，可以形象地称为雪崩。

![](http://assets.processon.com/chart_image/6270b9c91efad45d06d5096b.png)

缓存的高可用建设是非常重要的。

Redis 提供了主从和 Cluster 的模式，其中 Cluster 模式使用简单，每个分片也能单独做主从，可以保证极高的可用性。

另外，对数据库的性能瓶颈有一个大体的评估。如果缓存系统当掉，那么流向数据库的请求，就可以使用限流组件，将请求拦截在外面。

### 4. 缓存一致性

缓存组件，还会带来另一个老大难的问题，就是缓存的一致性。

对于一个缓存项，常用的操作有四个：**写入、更新、读取、删除**。
- **写入**：缓存和数据库是两个不同的组件，只要涉及双写，就存在只有一个写成功的可能性，造成数据不一致；
- **更新**：更新的情况类似，需要更新两个不同的组件；
- **读取**：读取要保证从缓存中读到的信息是更新的，是和数据库中的是一致的；
- **删除**：当删除数据库记录的时候，把缓存中的数据也删掉。

由于业务逻辑大多数情况下，是比较复杂的。其中的更新操作，就非常昂贵，比如一个用户的余额，就是通过计算一些系列的资产算出来的一个数。如果这些关联的资产，每个地方改动的时候，都去刷新缓存，那代码结构就会非常混乱，以至于无法维护。

解决这种方式，可以使用**触发式的缓存一致性方式**，使用**懒加载**的方式，可以让缓存的同步变得非常简单：
- 当读取缓存的时候，如果缓存里没有相关数据，则执行相关的业务逻辑，构造缓存数据存入到缓存系统；
- 当与缓存项相关的资源有变动，则先删除相应的缓存项，然后再对资源进行更新，这个时候，即使是资源更新失败，也是没有问题的。

这种操作，除了编程模型简单，有一个明显的好处。只有用到这个缓存的时候，才把它加载到缓存系统中。如果每次修改都创建、更新资源，那缓存系统中就会存在非常多的冷数据。

上面提到的缓存删除动作，和数据库的更新动作，明显是不在一个事务里的。

如果一个请求删除了缓存，同时有另外一个请求到来，此时发现没有相关的缓存项，就从数据库里加载了一份到缓存系统。接下来，数据库的更新操作也完成了，此时数据库的内容和缓存里的内容，就产生了不一致。

下面的图，直观地解释了这种不一致的情况，此时，缓存读取 B 操作以及之后的读取操作，都会读到错误的缓存值。
![缓存不一致](http://assets.processon.com/chart_image/6270c4f4f346fb6712b51440.png)

可以使用**分布式锁**来解决这个问题，将缓存操作和数据库删除操作，与其他的缓存读操作，使用锁进行资源隔离即可。一般来说，读操作是步不需要加锁的，它会遇到锁的时候，重试等待，直到超时。

> 所谓的一致性，就是最后总要有个收口的地方。
- 双删除操明显不能收口；
- Redis 的分布式锁性能特别高，能够应付大多数高并发场景
- 如果 Redis 单机有瓶颈，可以根据锁的内容（比如用户 ID），在近一步 hash 到多台机器上，采用分段的思想解决。这个分段思想不仅仅可以用在锁上，还能用在资源上。比如，把一个红包，先拆分成 100 份，然后每一批人分别对其中进行秒杀。
{: .prompt-info }


